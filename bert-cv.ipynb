{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Her göreve özel kullanılacak Simple Transformers modeli, kullanıcının modeli kendi kullanım durumlarına göre kolayca uyarlamasını sağlamak için tonlarca yapılandırma seçeneğiyle birlikte gelir.\n\"https://simpletransformers.ai/docs/usage/ \"","metadata":{}},{"cell_type":"code","source":"!pip install simpletransformers","metadata":{"execution":{"iopub.status.busy":"2022-08-19T02:11:09.286935Z","iopub.execute_input":"2022-08-19T02:11:09.287873Z","iopub.status.idle":"2022-08-19T02:11:41.698205Z","shell.execute_reply.started":"2022-08-19T02:11:09.287754Z","shell.execute_reply":"2022-08-19T02:11:41.696556Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Gerekli kütüphane ve metrikler tanımlandı","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:57:31.874615Z","iopub.execute_input":"2022-08-18T22:57:31.875116Z","iopub.status.idle":"2022-08-18T22:57:31.903812Z","shell.execute_reply.started":"2022-08-18T22:57:31.875003Z","shell.execute_reply":"2022-08-18T22:57:31.902534Z"}}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nimport torch\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import BertTokenizer,AdamW , BertForSequenceClassification\nfrom torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\nfrom sklearn.model_selection import StratifiedKFold\n\n\nimport datetime\nimport random\nimport seaborn as sns\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\n\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-08-19T02:11:41.701609Z","iopub.execute_input":"2022-08-19T02:11:41.702425Z","iopub.status.idle":"2022-08-19T02:11:51.329360Z","shell.execute_reply.started":"2022-08-19T02:11:41.702377Z","shell.execute_reply":"2022-08-19T02:11:51.327831Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"'dbmdz/bert-base-turkish-128k-uncased':\nvocab size -> 128k.   \nThe final training corpus has a size of 35GB and 44,04,976,662 tokens.","metadata":{}},{"cell_type":"markdown","source":"Temizlenmiş verinin kategorik etiketleri bir data frame e kaydedilip numerik olarak değiştirildi. ","metadata":{}},{"cell_type":"code","source":"# Dataset\ndf = pd.read_csv('datasets/clean_data.csv')\ndf['label'] = LabelEncoder().fit_transform(df['label'])","metadata":{"execution":{"iopub.status.busy":"2022-08-19T02:11:51.331296Z","iopub.execute_input":"2022-08-19T02:11:51.332455Z","iopub.status.idle":"2022-08-19T02:11:51.396766Z","shell.execute_reply.started":"2022-08-19T02:11:51.332419Z","shell.execute_reply":"2022-08-19T02:11:51.395472Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"önceden eğitilmiş sınıflandırıcılar download edildi . ","metadata":{}},{"cell_type":"code","source":"from simpletransformers.classification import ClassificationModel, ClassificationArgs\nfrom sklearn.model_selection import KFold\nfrom transformers import logging\nlogging.set_verbosity_error()\n\ntokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-128k-uncased', do_lower_case=True)\nmodel = BertForSequenceClassification.from_pretrained('dbmdz/bert-base-turkish-128k-uncased', num_labels=2)\n# https://simpletransformers.ai/docs/classification-specifics/#supported-model-types\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T02:11:51.401626Z","iopub.execute_input":"2022-08-19T02:11:51.401935Z","iopub.status.idle":"2022-08-19T02:13:12.017221Z","shell.execute_reply.started":"2022-08-19T02:11:51.401907Z","shell.execute_reply":"2022-08-19T02:13:12.015371Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# check GPU\ndevice_name = tf.test.gpu_device_name()\nif device_name == '/device:GPU:0':\n    device = torch.device(\"cuda\") #Current GPU;tensörleri ve modelleri cpu'dan gpu'ya taşır. \nelse:\n    raise SystemError('GPU device not found')","metadata":{"execution":{"iopub.status.busy":"2022-08-19T02:13:12.019338Z","iopub.execute_input":"2022-08-19T02:13:12.020960Z","iopub.status.idle":"2022-08-19T02:13:19.580757Z","shell.execute_reply.started":"2022-08-19T02:13:12.020883Z","shell.execute_reply":"2022-08-19T02:13:19.579285Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"GPU kullanıyor mu ? Memory size nedir ?","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-08-19T02:13:19.582572Z","iopub.execute_input":"2022-08-19T02:13:19.584732Z","iopub.status.idle":"2022-08-19T02:13:21.278481Z","shell.execute_reply.started":"2022-08-19T02:13:19.584686Z","shell.execute_reply":"2022-08-19T02:13:21.276922Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"clean datadaki her satır için encode edilmiş değerleri hesaplar.\ninput_ids ->verilen token pozisyonunun gerçek token içerip içermediğini veya sıfır dolgulu bir konum olup olmadığını gösterir.\nattention_mask yığındaki örneklerin uzunlukları farklı olsa bile, transformatöre bir yığın göndermemize olanak tanır. \n\n0'ları dolgu jetonlarının konumlarına ve 1'leri gerçek jetonların konumlarına yerleştirerek hengi input_ids lerin dummy olduğunu belirler. \n\n#max_length=10 olsun . [101, 2026, 2171, 2003, 11754, 102, 0, 0, 0, 0], 101:[CLS]ve 102:[SEP]  olduğu ifadeye karşılık gelir. \n\n\nencode_plus-> encode-dan farkı tokenizer ve kelimeleri kullanarak bir string-i, bir dizi id e çevirir, modelin iki diziyi ayırt etmesine izin veren bir tür maskeleme bekler\n","metadata":{}},{"cell_type":"code","source":"input_ids = []\nattention_masks = []\nmax_len = 60 \n\nfor text in df['clean_data']:\n    encoded_dict = tokenizer.encode_plus(\n                        str(text),                     \n                        add_special_tokens = True,\n                        max_length = max_len,      \n                        pad_to_max_length = True,\n                        return_attention_mask = True, \n                        return_tensors = 'pt',\n                   )\n    \n    input_ids.append(encoded_dict['input_ids'])\n    attention_masks.append(encoded_dict['attention_mask'])\n\ninput_ids = torch.cat(input_ids, dim=0)#Verilen boyutta(0) tensör dizisini birleştirir .\nattention_masks = torch.cat(attention_masks, dim=0)\nlabels = torch.tensor(df['label'])\n\nprint('Original: ', df['clean_data'][0])\nprint('Token IDs:', input_ids[0])\nprint(labels[0])","metadata":{"execution":{"iopub.status.busy":"2022-08-19T02:13:21.280461Z","iopub.execute_input":"2022-08-19T02:13:21.281265Z","iopub.status.idle":"2022-08-19T02:13:24.266615Z","shell.execute_reply.started":"2022-08-19T02:13:21.281218Z","shell.execute_reply":"2022-08-19T02:13:24.265145Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Stratified K fold kullanılarak farklı etiketlerin verideki dağılımları dikkate alınmış oldu, 10 a bölündü . \nVeri artık input_ids ve labels isimli tensörlerden oluşmakta. Tensör nesneleri ile oluşan data frame sınıflandırıcıya verildi. ","metadata":{}},{"cell_type":"code","source":"\nskf = StratifiedKFold(n_splits=10)\nresults = []\ntrain_data = pd.DataFrame(columns=['texts','labels'])\ntrain_data['texts'] = df.clean_data\ntrain_data['labels'] = df.label\nfor train_index, val_index in skf.split(train_data['texts'], train_data['labels']):\n  # splitting Dataframe (dataset not included)\n    train_df = train_data.iloc[train_index]\n    val_df = train_data.iloc[val_index]\n    # Defining Model\n    model = ClassificationModel('bert', 'dbmdz/bert-base-turkish-128k-uncased', num_labels=4,\n                                args={'reprocess_input_data': True, 'overwrite_output_dir': True, \n                                      'num_train_epochs': 5, \"train_batch_size\": 64 , \n                                      \"output_dir\": \"bert_model\", \"learning_rate\": 5e-5, \n                                      \"load_best_model_at_end\": True, \"use_early_stopping\":True, \"early_stopping_delta\": 0.01,\n                                     \"max_length\": 60, \"tokenizer_name\": tokenizer }, use_cuda=True, random_state = 42)\n  # train the model\n    model.train_model(train_df)\n  # validate the model \n    result, model_outputs, wrong_predictions = model.eval_model(val_df, acc=accuracy_score)\n    print(f'Acc : {result[\"acc\"]}')\n  # append model score\n    results.append(result[\"acc\"])\n\n\nprint(\"results\",results)\nprint(f\"Mean-Precision: {sum(results) / len(results)}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T02:13:24.268753Z","iopub.execute_input":"2022-08-19T02:13:24.269433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.get_named_parameters()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model_outputs.argmax(axis=1)\nactuals = val_df.labels.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nprint(classification_report(actuals, predictions, digits=3))\nprint(balanced_accuracy_score(actuals, predictions))\ncm = confusion_matrix(actuals, predictions, labels=[0,1,2,3])\nprint(cm)\ntn, fp, fn, tp = cm\nprint((tn, fp, fn, tp))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=[0,1,2,3])\ndisp.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}